<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scaling Laws for Landscape Geometry</title>
    <link rel="stylesheet" href="../style.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-annotation"></script>
</head>
<body>
<nav>
    <div class="nav-inner">
        <a href="../index.html" class="site-title">~ failing at ml research</a>
        <a href="../index.html">posts</a>
        <a href="about.html">about</a>
    </div>
</nav>
<div class="container">

<h1>Scaling Laws for Landscape Geometry</h1>
<p class="post-date">February 2026</p>
<p class="subtitle">I swept 4 architectural variables across 5 values each, measuring 9 landscape properties per configuration. Here are the power laws.</p>

<h2>Method</h2>

<p>For each sweep, I varied one architectural parameter while holding others constant. Each configuration was trained for 500 steps with Muon, then measured: loss, sharpness, gradient SNR, inter-batch alignment, noise effective dimensionality, gradient effective rank, gradient norm, distance from initialization, and lm_head sensitivity ratio.</p>

<p>Power laws were fit as y = a &middot; x<sup>b</sup>. Only relationships with R&sup2; &gt; 0.9 are reported as "strong."</p>

<details>
<summary>Sweep configuration generation code</summary>
<pre><code># Sweep 1: Width (d_model)
# Fix: n_layers=4, vocab=4096, batch=64, n_heads scales with d_model
configs = []
for d in [64, 128, 256, 512]:
    configs.append(dict(
        d_model=d, n_layers=4, n_heads=max(2, d // 64), d_ff=d * 4,
        vocab_size=4096, batch_size=64, lr_muon=0.005
    ))

# Sweep 2: Depth (n_layers)
# Fix: d_model=256, vocab=4096, batch=64
configs = []
for L in [1, 2, 4, 8, 12]:
    configs.append(dict(
        d_model=256, n_layers=L, n_heads=4, d_ff=1024,
        vocab_size=4096, batch_size=64, lr_muon=0.005
    ))

# Sweep 3: Batch Size
# Fix: d_model=256, n_layers=4, vocab=4096
configs = []
for B in [8, 16, 32, 64, 128, 256]:
    configs.append(dict(
        d_model=256, n_layers=4, n_heads=4, d_ff=1024,
        vocab_size=4096, batch_size=B, lr_muon=0.005
    ))

# Sweep 4: Vocab Size
# Fix: d_model=256, n_layers=4, batch=64
configs = []
for V in [512, 1024, 2048, 4096, 8192]:
    configs.append(dict(
        d_model=256, n_layers=4, n_heads=4, d_ff=1024,
        vocab_size=V, batch_size=64, lr_muon=0.005
    ))</code></pre>
</details>

<details>
<summary>Training and measurement code (train_and_measure)</summary>
<pre><code>DEVICE = torch.device("mps")
SEQ = 128
SEED = 42
TRAIN_STEPS = 500

def train_and_measure(d_model, n_layers, n_heads, d_ff,
                      vocab_size, batch_size, lr_muon=0.005):
    """Train a model and measure landscape properties."""
    torch.manual_seed(SEED)

    model = SmallGPT(
        vocab_size=vocab_size, d_model=d_model, n_heads=n_heads,
        n_layers=n_layers, d_ff=d_ff, max_seq=SEQ + 16
    ).to(DEVICE)

    n_params = model.param_count()
    data = make_synthetic_data(
        n_samples=3000, seq_len=SEQ + 1, vocab_size=vocab_size
    ).to(DEVICE)

    # Muon for 2D params, Adam for everything else
    params_2d = [p for n, p in model.named_parameters() if p.ndim == 2]
    params_other = [p for n, p in model.named_parameters() if p.ndim != 2]
    opt = SingleDeviceSpectraMuonWithAuxAdam([
        dict(params=params_other, lr=1e-3, betas=(0.9, 0.95),
             eps=1e-10, use_muon=False),
        dict(params=params_2d, lr=lr_muon, momentum=0.95,
             alpha=0.0, use_muon=True),
    ])

    init_params = torch.cat(
        [p.data.flatten().float().cpu() for p in model.parameters()]
    ).clone()

    # Train
    for step in range(TRAIN_STEPS):
        idx = torch.randint(0, len(data), (batch_size,), device=DEVICE)
        batch = data[idx]
        opt.zero_grad(set_to_none=True)
        _, loss = model(batch[:, :-1], batch[:, 1:])
        loss.backward()
        opt.step()

    # === Measurements ===
    results = {"n_params": n_params}

    # 1. Final loss (averaged over 10 batches)
    total_loss = 0
    with torch.no_grad():
        for _ in range(10):
            idx = torch.randint(0, len(data), (batch_size,), device=DEVICE)
            batch = data[idx]
            _, l = model(batch[:, :-1], batch[:, 1:])
            total_loss += l.item()
    results["loss"] = total_loss / 10

    # 2. Distance from init
    final_params = torch.cat(
        [p.data.flatten().float().cpu() for p in model.parameters()]
    )
    results["dist_from_init"] = (final_params - init_params).norm().item()

    # 3. Sharpness (avg loss increase at scale 0.01)
    #    10 random filter-normalized directions
    center = torch.cat([p.data.flatten() for p in model.parameters()])
    deltas = []
    for d in range(10):
        torch.manual_seed(SEED + d + 7000)
        direction = []
        for p in model.parameters():
            r = torch.randn_like(p)
            if p.ndim >= 2:
                r = r * (p.data.norm() / (r.norm() + 1e-10))
            direction.append(r.flatten())
        direction = torch.cat(direction)

        # Perturb, measure, restore
        offset = 0
        for p in model.parameters():
            n = p.numel()
            p.data.copy_(
                (center[offset:offset+n] + 0.01 * direction[offset:offset+n])
                .reshape(p.shape)
            )
            offset += n

        with torch.no_grad():
            idx = torch.randint(0, len(data), (batch_size,), device=DEVICE)
            batch = data[idx]
            _, l = model(batch[:, :-1], batch[:, 1:])
            deltas.append(l.item() - results["loss"])

        # Restore center
        offset = 0
        for p in model.parameters():
            n = p.numel()
            p.data.copy_(center[offset:offset+n].reshape(p.shape))
            offset += n

    results["sharpness"] = np.mean(deltas)

    # 4. Gradient SNR and noise structure (20 micro-batches)
    all_grads = []
    for i in range(20):
        idx = torch.randint(0, len(data), (batch_size,), device=DEVICE)
        batch = data[idx]
        model.zero_grad(set_to_none=True)
        _, l = model(batch[:, :-1], batch[:, 1:])
        l.backward()
        g = torch.cat(
            [p.grad.flatten().float().cpu()
             for p in model.parameters() if p.grad is not None]
        )
        all_grads.append(g)

    grads = torch.stack(all_grads)
    mean_grad = grads.mean(dim=0)
    noise = grads - mean_grad
    signal_norm = mean_grad.norm().item()
    noise_norm = noise.norm(dim=1).mean().item()
    results["grad_snr"] = signal_norm / (noise_norm + 1e-10)

    # Inter-batch alignment (pairwise cosine sim)
    aligns = []
    for i in range(10):
        for j in range(i+1, 10):
            aligns.append(
                F.cosine_similarity(grads[i], grads[j], dim=0).item()
            )
    results["inter_batch_align"] = np.mean(aligns)

    # Noise dimensionality (via SVD)
    _, S, _ = torch.linalg.svd(noise, full_matrices=False)
    total_var = (S**2).sum().item()
    results["noise_eff_dim"] = total_var / (S[0]**2).item()

    # Gradient effective rank (per 2D layer)
    ranks = []
    offset = 0
    for name, p in model.named_parameters():
        n = p.numel()
        if p.ndim >= 2:
            g = mean_grad[offset:offset+n].reshape(p.shape)
            svs = torch.linalg.svdvals(g)
            if svs[0] > 1e-10:
                ranks.append(((svs**2).sum() / svs[0]**2).item())
        offset += n
    results["grad_eff_rank"] = np.mean(ranks)

    # 5. Gradient norm
    results["grad_norm"] = mean_grad.norm().item()

    # 6. lm_head sensitivity ratio
    for name, p in model.named_parameters():
        if p.ndim < 2:
            continue
        saved = p.data.clone()
        noise = torch.randn_like(p) * 0.01 * p.data.norm()
        p.data.add_(noise)
        with torch.no_grad():
            _, l = model(batch[:, :-1], batch[:, 1:])
            delta = l.item() - results["loss"]
        p.data.copy_(saved)
        if "lm_head" in name:
            lm_head_delta = delta
        else:
            other_deltas.append(delta)
    results["lm_head_ratio"] = lm_head_delta / np.mean(other_deltas)

    return results</code></pre>
</details>

<details>
<summary>Power law fitting code</summary>
<pre><code>def power_law_fit(x, y):
    """Fit y = a * x^b. Return (a, b, r_squared)."""
    x, y = np.array(x, dtype=float), np.array(y, dtype=float)
    mask = (x > 0) & (y > 0) & np.isfinite(x) & np.isfinite(y)
    if mask.sum() < 2:
        return 0, 0, 0
    lx, ly = np.log(x[mask]), np.log(y[mask])
    if len(lx) < 2:
        return 0, 0, 0
    b, a_log = np.polyfit(lx, ly, 1)
    a = np.exp(a_log)
    # R-squared
    y_pred = a * x[mask]**b
    ss_res = np.sum((y[mask] - y_pred)**2)
    ss_tot = np.sum((y[mask] - np.mean(y[mask]))**2)
    r2 = 1 - ss_res / (ss_tot + 1e-10)
    return a, b, r2</code></pre>
<p>The fit is linear regression in log-log space: log(y) = b&middot;log(x) + log(a). Simple, fast, and it gives us the exponent b directly. R&sup2; is computed in the original (non-log) space to avoid misleading goodness-of-fit from log compression.</p>
</details>

<h2>Depth (n_layers: 1, 2, 4, 8, 12)</h2>

<table>
    <tr><th>Depth</th><th>Params</th><th>Loss</th><th>SNR</th><th>Rank</th><th>Alignment</th><th>lm_head ratio</th></tr>
    <tr><td>1</td><td>2.9M</td><td>4.09</td><td>0.36</td><td>25.8</td><td>0.070</td><td>12.9</td></tr>
    <tr><td>2</td><td>3.7M</td><td>3.66</td><td>0.40</td><td>15.3</td><td>0.097</td><td>13.1</td></tr>
    <tr><td>4</td><td>5.3M</td><td>3.14</td><td>0.41</td><td>11.4</td><td>0.099</td><td>13.6</td></tr>
    <tr><td>8</td><td>8.4M</td><td>2.65</td><td>0.46</td><td>8.6</td><td>0.128</td><td>15.1</td></tr>
    <tr><td>12</td><td>11.6M</td><td>2.47</td><td>0.51</td><td>6.5</td><td>0.171</td><td>17.3</td></tr>
</table>

<div style="max-width:700px;margin:20px auto;"><canvas id="depthLossChart"></canvas></div>

<pre><code>loss      ~ n_layers^-0.21  (R&sup2;=0.994) STRONG
grad_snr  ~ n_layers^+0.13  (R&sup2;=0.947) STRONG
grad_rank ~ n_layers^-0.53  (R&sup2;=0.978) STRONG
alignment ~ n_layers^+0.32  (R&sup2;=0.916) STRONG
grad_norm ~ n_layers^+0.24  (R&sup2;=0.988) STRONG</code></pre>

<div style="max-width:700px;margin:20px auto;"><canvas id="depthRankChart"></canvas></div>

<p>Deeper models have better gradient quality: higher SNR, better inter-batch alignment, and lower gradient rank (more concentrated signal). Depth acts as a noise filter &mdash; each additional layer concentrates the gradient into fewer dimensions while improving its signal quality.</p>

<div class="callout callout-green">
<strong>Strongest result:</strong> Gradient rank scales as ~1/&radic;depth (exponent -0.53, R&sup2;=0.978). A 12-layer model has gradient rank 6.5 vs a 1-layer model's 25.8. The gradient becomes increasingly low-rank with depth.
</div>

<details>
<summary>Full raw data: Depth sweep (all 9 metrics)</summary>
<table>
    <tr>
        <th>n_layers</th><th>loss</th><th>sharpness</th><th>grad_snr</th><th>align</th>
        <th>noise_dim</th><th>grad_rank</th><th>grad_norm</th><th>dist_init</th><th>lm_ratio</th><th>n_params</th>
    </tr>
    <tr>
        <td>1</td><td>4.0885</td><td>0.0075</td><td>0.3608</td><td>0.0699</td>
        <td>16.2808</td><td>25.7561</td><td>0.5953</td><td>95.9663</td><td>12.9440</td><td>2,921,984</td>
    </tr>
    <tr>
        <td>2</td><td>3.6572</td><td>0.0926</td><td>0.4009</td><td>0.0965</td>
        <td>16.3170</td><td>15.2778</td><td>0.7660</td><td>99.2949</td><td>13.1105</td><td>3,709,440</td>
    </tr>
    <tr>
        <td>4</td><td>3.1366</td><td>-0.1034</td><td>0.4107</td><td>0.0990</td>
        <td>15.6745</td><td>11.3572</td><td>0.8684</td><td>105.2206</td><td>13.6260</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>8</td><td>2.6503</td><td>0.0435</td><td>0.4626</td><td>0.1275</td>
        <td>15.4085</td><td>8.5602</td><td>1.0088</td><td>116.1069</td><td>15.0936</td><td>8,434,176</td>
    </tr>
    <tr>
        <td>12</td><td>2.4727</td><td>0.0285</td><td>0.5110</td><td>0.1705</td>
        <td>15.7770</td><td>6.4558</td><td>1.1192</td><td>126.8141</td><td>17.3262</td><td>11,584,000</td>
    </tr>
</table>
<pre><code>Power law fits: y = a * n_layers^b
Metric                        a   b (exponent)       R^2  Relationship
loss                     4.1507         -0.209    0.994  ~ n_layers^-0.21 (STRONG)
sharpness                                        -0.281  no clear relationship
grad_snr                 0.3585          0.130    0.947  ~ n_layers^0.13 (STRONG)
inter_batch_align        0.0705          0.319    0.916  ~ n_layers^0.32 (STRONG)
noise_eff_dim           16.3145         -0.020    0.660  ~ constant (moderate)
grad_eff_rank           24.0979         -0.526    0.978  ~ 1/sqrt(n_layers) (STRONG)
grad_norm                0.6169          0.242    0.988  ~ n_layers^0.24 (STRONG)
dist_from_init          93.3763          0.110    0.939  ~ n_layers^0.11 (STRONG)
lm_head_ratio           12.3863          0.110    0.825  ~ n_layers^0.11 (moderate)</code></pre>
</details>

<h2>Batch size (8, 16, 32, 64, 128, 256)</h2>

<table>
    <tr><th>Batch</th><th>Loss</th><th>SNR</th><th>Alignment</th><th>lm_head ratio</th><th>Dist from init</th></tr>
    <tr><td>8</td><td>7.68</td><td>0.28</td><td>0.024</td><td>61.6</td><td>73.7</td></tr>
    <tr><td>16</td><td>6.87</td><td>0.30</td><td>0.039</td><td>35.8</td><td>78.0</td></tr>
    <tr><td>32</td><td>5.27</td><td>0.35</td><td>0.067</td><td>19.7</td><td>88.8</td></tr>
    <tr><td>64</td><td>3.14</td><td>0.41</td><td>0.101</td><td>13.6</td><td>105.2</td></tr>
    <tr><td>128</td><td>1.29</td><td>0.57</td><td>0.205</td><td>11.0</td><td>122.7</td></tr>
    <tr><td>256</td><td>0.32</td><td>0.69</td><td>0.288</td><td>9.9</td><td>136.3</td></tr>
</table>

<div style="max-width:700px;margin:20px auto;"><canvas id="batchAlignChart"></canvas></div>

<pre><code>grad_snr       ~ batch_size^+0.27  (R&sup2;=0.972) STRONG
alignment      ~ batch_size^+0.74  (R&sup2;=0.985) STRONG
lm_head_ratio  ~ batch_size^-0.54  (R&sup2;=0.926) STRONG
dist_from_init ~ batch_size^+0.19  (R&sup2;=0.989) STRONG</code></pre>

<p>Inter-batch alignment scales as batch_size<sup>0.74</sup> &mdash; nearly linear. Doubling batch size nearly doubles the directional consistency of consecutive gradients. At batch size 8, alignment is just 2.4% (gradients are essentially random). At 256, it reaches 28.8%.</p>

<p>lm_head sensitivity drops as ~1/&radic;batch_size. Larger batches naturally tame the lm_head problem by averaging out its noisy gradients.</p>

<details>
<summary>Full raw data: Batch size sweep (all 9 metrics)</summary>
<table>
    <tr>
        <th>batch</th><th>loss</th><th>sharpness</th><th>grad_snr</th><th>align</th>
        <th>noise_dim</th><th>grad_rank</th><th>grad_norm</th><th>dist_init</th><th>lm_ratio</th><th>n_params</th>
    </tr>
    <tr>
        <td>8</td><td>7.6792</td><td>0.0460</td><td>0.2767</td><td>0.0237</td>
        <td>15.7028</td><td>9.2045</td><td>0.3191</td><td>73.6928</td><td>61.6144</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>16</td><td>6.8664</td><td>-0.1360</td><td>0.3024</td><td>0.0393</td>
        <td>16.2167</td><td>9.8401</td><td>0.4215</td><td>78.0461</td><td>35.8124</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>32</td><td>5.2701</td><td>-0.0581</td><td>0.3545</td><td>0.0670</td>
        <td>16.1212</td><td>10.0619</td><td>0.6534</td><td>88.7862</td><td>19.7493</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>64</td><td>3.1354</td><td>-0.1028</td><td>0.4136</td><td>0.1009</td>
        <td>15.6822</td><td>11.2189</td><td>0.8743</td><td>105.2208</td><td>13.6194</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>128</td><td>1.2942</td><td>0.0430</td><td>0.5665</td><td>0.2047</td>
        <td>14.5388</td><td>9.0498</td><td>0.9933</td><td>122.6648</td><td>11.0477</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>256</td><td>0.3202</td><td>0.0472</td><td>0.6852</td><td>0.2880</td>
        <td>14.9005</td><td>9.5430</td><td>0.6610</td><td>136.2709</td><td>9.9456</td><td>5,284,352</td>
    </tr>
</table>
<pre><code>Power law fits: y = a * batch_size^b
Metric                        a   b (exponent)       R^2  Relationship
loss                                              0.427  no clear relationship
sharpness                                         0.004  no clear relationship
grad_snr                 0.1461          0.271    0.972  ~ batch_size^0.27 (STRONG)
inter_batch_align        0.0051          0.736    0.985  ~ batch_size^0.74 (STRONG)
noise_eff_dim           17.0957         -0.025    0.563  ~ constant (moderate)
grad_eff_rank                                    -0.000  no clear relationship
grad_norm                                         0.430  no clear relationship
dist_from_init          47.6751          0.190    0.989  ~ batch_size^0.19 (STRONG)
lm_head_ratio          155.1904         -0.537    0.926  ~ 1/sqrt(batch_size) (STRONG)</code></pre>
</details>

<h2>Vocab size (512, 1024, 2048, 4096, 8192)</h2>

<table>
    <tr><th>Vocab</th><th>Params</th><th>Loss</th><th>Rank</th><th>lm_head ratio</th><th>Dist from init</th></tr>
    <tr><td>512</td><td>3.4M</td><td>3.25</td><td>5.8</td><td>3.7</td><td>59.4</td></tr>
    <tr><td>1024</td><td>3.7M</td><td>3.45</td><td>7.0</td><td>6.0</td><td>67.1</td></tr>
    <tr><td>2048</td><td>4.2M</td><td>3.48</td><td>9.0</td><td>9.5</td><td>81.5</td></tr>
    <tr><td>4096</td><td>5.3M</td><td>3.14</td><td>11.2</td><td>13.6</td><td>105.2</td></tr>
    <tr><td>8192</td><td>7.4M</td><td>2.30</td><td>11.9</td><td>18.9</td><td>142.7</td></tr>
</table>

<div style="max-width:700px;margin:20px auto;"><canvas id="vocabLmHeadChart"></canvas></div>

<pre><code>lm_head_ratio  ~ vocab_size^+0.59  (R&sup2;=0.987) STRONG
dist_from_init ~ vocab_size^+0.32  (R&sup2;=0.974) STRONG
grad_rank      ~ vocab_size^+0.28  (R&sup2;=0.947) STRONG</code></pre>

<p>lm_head sensitivity grows as ~&radic;vocab_size. This makes sense: lm_head has vocab_size &times; d_model parameters, so its share of total params (and thus its influence on loss) grows with vocab. Models with large vocabularies need stronger lm_head treatment.</p>

<details>
<summary>Full raw data: Vocab size sweep (all 9 metrics)</summary>
<table>
    <tr>
        <th>vocab</th><th>loss</th><th>sharpness</th><th>grad_snr</th><th>align</th>
        <th>noise_dim</th><th>grad_rank</th><th>grad_norm</th><th>dist_init</th><th>lm_ratio</th><th>n_params</th>
    </tr>
    <tr>
        <td>512</td><td>3.2536</td><td>-0.0481</td><td>0.4314</td><td>0.1155</td>
        <td>16.2426</td><td>5.7768</td><td>0.9886</td><td>59.4103</td><td>3.6639</td><td>3,449,344</td>
    </tr>
    <tr>
        <td>1024</td><td>3.4494</td><td>-0.0688</td><td>0.4480</td><td>0.1266</td>
        <td>16.2513</td><td>6.9996</td><td>1.0579</td><td>67.0895</td><td>6.0211</td><td>3,711,488</td>
    </tr>
    <tr>
        <td>2048</td><td>3.4795</td><td>-0.0747</td><td>0.4539</td><td>0.1316</td>
        <td>15.9692</td><td>9.0368</td><td>1.0375</td><td>81.4833</td><td>9.5054</td><td>4,235,776</td>
    </tr>
    <tr>
        <td>4096</td><td>3.1363</td><td>-0.1028</td><td>0.4134</td><td>0.1001</td>
        <td>15.6513</td><td>11.2373</td><td>0.8739</td><td>105.2195</td><td>13.6174</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>8192</td><td>2.2981</td><td>-0.0996</td><td>0.4370</td><td>0.1119</td>
        <td>15.3342</td><td>11.8569</td><td>0.7714</td><td>142.7208</td><td>18.8959</td><td>7,381,504</td>
    </tr>
</table>
<pre><code>Power law fits: y = a * vocab_size^b
Metric                        a   b (exponent)       R^2  Relationship
loss                                              0.472  no clear relationship
sharpness                                         0.000  no clear relationship
grad_snr                                          0.054  no clear relationship
inter_batch_align                                 0.176  no clear relationship
noise_eff_dim           18.7917         -0.022    0.927  ~ constant (STRONG)
grad_eff_rank            1.0576          0.276    0.947  ~ vocab_size^0.28 (STRONG)
grad_norm                2.0004         -0.099    0.615  ~ constant (moderate)
dist_from_init           7.6784          0.318    0.974  ~ vocab_size^0.32 (STRONG)
lm_head_ratio            0.0975          0.591    0.987  ~ sqrt(vocab_size) (STRONG)</code></pre>
</details>

<h2>Width (d_model: 64, 128, 256, 512)</h2>

<pre><code>dist_from_init ~ d_model^+0.25  (R&sup2;=0.978) STRONG
lm_head_ratio  ~ d_model^-0.82  (R&sup2;=0.844) moderate
grad_rank      ~ d_model^+0.12  (R&sup2;=0.819) moderate</code></pre>

<p>Width shows weaker scaling than depth or batch size. The clearest relationship: wider models travel farther from initialization (~d_model<sup>0.25</sup>). lm_head sensitivity decreases with width because the non-lm_head parameters grow faster than lm_head (d_model&sup2; vs vocab &times; d_model).</p>

<details>
<summary>Full raw data: Width sweep (all 9 metrics)</summary>
<table>
    <tr>
        <th>d_model</th><th>loss</th><th>sharpness</th><th>grad_snr</th><th>align</th>
        <th>noise_dim</th><th>grad_rank</th><th>grad_norm</th><th>dist_init</th><th>lm_ratio</th><th>n_params</th>
    </tr>
    <tr>
        <td>64</td><td>7.3309</td><td>-0.0444</td><td>0.4158</td><td>0.0949</td>
        <td>16.2268</td><td>8.9798</td><td>0.2038</td><td>69.9227</td><td>71.5944</td><td>731,264</td>
    </tr>
    <tr>
        <td>128</td><td>6.0165</td><td>-0.0389</td><td>0.4271</td><td>0.1166</td>
        <td>15.8220</td><td>9.4271</td><td>0.4939</td><td>86.5521</td><td>23.6920</td><td>1,855,744</td>
    </tr>
    <tr>
        <td>256</td><td>3.1363</td><td>-0.1032</td><td>0.4135</td><td>0.1009</td>
        <td>15.6664</td><td>11.2330</td><td>0.8741</td><td>105.2214</td><td>13.6152</td><td>5,284,352</td>
    </tr>
    <tr>
        <td>512</td><td>0.7055</td><td>-0.0542</td><td>0.3933</td><td>0.0831</td>
        <td>13.2361</td><td>11.0574</td><td>0.6528</td><td>117.8063</td><td>13.0514</td><td>16,860,160</td>
    </tr>
</table>
<pre><code>Power law fits: y = a * d_model^b
Metric                        a   b (exponent)       R^2  Relationship
loss                   993.1424         -1.107    0.627  ~ 1/d_model (moderate)
sharpness                                         0.000  no clear relationship
grad_snr                 0.4787         -0.029    0.545  ~ constant (moderate)
inter_batch_align                                 0.201  no clear relationship
noise_eff_dim           24.2015         -0.090    0.733  ~ constant (moderate)
grad_eff_rank            5.5589          0.115    0.819  ~ d_model^0.12 (moderate)
grad_norm                                         0.374  no clear relationship
dist_from_init          24.8562          0.254    0.978  ~ d_model^0.25 (STRONG)
lm_head_ratio         1634.8376         -0.817    0.844  ~ d_model^-0.82 (moderate)</code></pre>
</details>

<h2>Training steps (landscape evolution)</h2>

<details>
<summary>Raw data: How landscape properties evolve during training</summary>
<p>Fixed architecture: d_model=256, n_layers=4, vocab=4096, batch=64. Muon optimizer at lr=0.005.</p>
<table>
    <tr><th>Steps</th><th>Loss</th><th>Dist from init</th><th>Grad SNR</th><th>Grad norm</th></tr>
    <tr><td>50</td><td>8.1267</td><td>18.29</td><td>0.4812</td><td>0.1781</td></tr>
    <tr><td>100</td><td>7.8250</td><td>30.44</td><td>0.4095</td><td>0.1781</td></tr>
    <tr><td>200</td><td>6.9292</td><td>49.91</td><td>0.4427</td><td>0.3330</td></tr>
    <tr><td>500</td><td>3.1148</td><td>105.21</td><td>0.4594</td><td>0.9595</td></tr>
    <tr><td>1000</td><td>0.8174</td><td>155.76</td><td>0.4340</td><td>0.9279</td></tr>
</table>
<p>Distance from init grows roughly as steps<sup>0.7</sup>. Gradient SNR stays nearly constant (~0.43-0.48) throughout training &mdash; the signal and noise grow together. Gradient norm peaks around step 500 then slightly decreases as the model converges.</p>
</details>

<h2>What doesn't scale cleanly</h2>

<p>Sharpness showed no clean relationship with any variable (R&sup2; &lt; 0.5 everywhere). Noise effective dimensionality was essentially constant (~15-16) across all sweeps, which we later determined was a measurement artifact of using only 20 gradient samples.</p>

<details>
<summary>Grand summary: All strong power laws (R^2 > 0.8)</summary>
<pre><code>WIDTH (d_model):
  grad_eff_rank          ~ d_model^  0.12  (R^2=0.819)
  dist_from_init         ~ d_model^  0.25  (R^2=0.978)
  lm_head_ratio          ~ d_model^ -0.82  (R^2=0.844)

DEPTH (n_layers):
  loss                   ~ n_layers^ -0.21  (R^2=0.994)
  grad_snr               ~ n_layers^  0.13  (R^2=0.947)
  inter_batch_align      ~ n_layers^  0.32  (R^2=0.916)
  grad_eff_rank          ~ n_layers^ -0.53  (R^2=0.978)
  grad_norm              ~ n_layers^  0.24  (R^2=0.988)
  dist_from_init         ~ n_layers^  0.11  (R^2=0.939)
  lm_head_ratio          ~ n_layers^  0.11  (R^2=0.825)

BATCH (batch_size):
  grad_snr               ~ batch_size^  0.27  (R^2=0.972)
  inter_batch_align      ~ batch_size^  0.74  (R^2=0.985)
  dist_from_init         ~ batch_size^  0.19  (R^2=0.989)
  lm_head_ratio          ~ batch_size^ -0.54  (R^2=0.926)

VOCAB (vocab_size):
  noise_eff_dim          ~ vocab_size^ -0.02  (R^2=0.927)
  grad_eff_rank          ~ vocab_size^  0.28  (R^2=0.947)
  dist_from_init         ~ vocab_size^  0.32  (R^2=0.974)
  lm_head_ratio          ~ vocab_size^  0.59  (R^2=0.987)</code></pre>
<p>Total experiment time: 44.6 minutes across all sweeps (21 configurations).</p>
</details>

<div class="page-nav">
    <a href="fingerprints.html">&larr; Prev: Optimizer Fingerprints</a>
    <a href="toy-vs-real.html">Next: Toy vs Real &rarr;</a>
</div>

<footer>
    <p>Built with real experiments, not theory.<br>February 2026</p>
</footer>

</div>

<script>
Chart.defaults.font.family = "'Courier Prime', monospace";

// --- Chart 1: Depth vs Loss (log-log) ---
(function() {
    var ctx = document.getElementById('depthLossChart').getContext('2d');
    var dataPoints = [
        {x: 1, y: 4.09},
        {x: 2, y: 3.66},
        {x: 4, y: 3.14},
        {x: 8, y: 2.65},
        {x: 12, y: 2.47}
    ];
    // Fit line: loss = 4.15 * depth^(-0.21)
    var fitPoints = [];
    for (var d = 1; d <= 12; d += 0.1) {
        fitPoints.push({x: d, y: 4.15 * Math.pow(d, -0.21)});
    }
    new Chart(ctx, {
        type: 'scatter',
        data: {
            datasets: [
                {
                    label: 'Measured',
                    data: dataPoints,
                    backgroundColor: '#8b4513',
                    borderColor: '#8b4513',
                    pointRadius: 6,
                    pointHoverRadius: 8,
                    order: 1
                },
                {
                    label: 'Fit: 4.15 \u00b7 depth\u207b\u00b0\u00b7\u00b2\u00b9',
                    data: fitPoints,
                    type: 'line',
                    borderColor: '#8b4513',
                    borderWidth: 1.5,
                    pointRadius: 0,
                    fill: false,
                    tension: 0,
                    order: 2
                }
            ]
        },
        options: {
            responsive: true,
            plugins: {
                title: {
                    display: true,
                    text: 'Loss ~ depth\u207b\u00b0\u00b7\u00b2\u00b9 (R\u00b2=0.994)',
                    font: { size: 15 }
                },
                legend: { display: false }
            },
            scales: {
                x: {
                    type: 'logarithmic',
                    title: { display: true, text: 'Depth (n_layers)' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                },
                y: {
                    type: 'logarithmic',
                    title: { display: true, text: 'Loss' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                }
            }
        }
    });
})();

// --- Chart 2: Depth vs Gradient Rank (log-log) ---
(function() {
    var ctx = document.getElementById('depthRankChart').getContext('2d');
    var dataPoints = [
        {x: 1, y: 25.8},
        {x: 2, y: 15.3},
        {x: 4, y: 11.4},
        {x: 8, y: 8.6},
        {x: 12, y: 6.5}
    ];
    // Fit line: rank = 24.1 * depth^(-0.53)
    var fitPoints = [];
    for (var d = 1; d <= 12; d += 0.1) {
        fitPoints.push({x: d, y: 24.1 * Math.pow(d, -0.53)});
    }
    new Chart(ctx, {
        type: 'scatter',
        data: {
            datasets: [
                {
                    label: 'Measured',
                    data: dataPoints,
                    backgroundColor: '#2d6a30',
                    borderColor: '#2d6a30',
                    pointRadius: 6,
                    pointHoverRadius: 8,
                    order: 1
                },
                {
                    label: 'Fit: 24.1 \u00b7 depth\u207b\u00b0\u00b7\u2075\u00b3',
                    data: fitPoints,
                    type: 'line',
                    borderColor: '#2d6a30',
                    borderWidth: 1.5,
                    pointRadius: 0,
                    fill: false,
                    tension: 0,
                    order: 2
                }
            ]
        },
        options: {
            responsive: true,
            plugins: {
                title: {
                    display: true,
                    text: 'Gradient rank ~ depth\u207b\u00b0\u00b7\u2075\u00b3 (R\u00b2=0.978)',
                    font: { size: 15 }
                },
                legend: { display: false }
            },
            scales: {
                x: {
                    type: 'logarithmic',
                    title: { display: true, text: 'Depth (n_layers)' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                },
                y: {
                    type: 'logarithmic',
                    title: { display: true, text: 'Gradient Effective Rank' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                }
            }
        }
    });
})();

// --- Chart 3: Batch Size vs Alignment (log-log) ---
(function() {
    var ctx = document.getElementById('batchAlignChart').getContext('2d');
    var dataPoints = [
        {x: 8, y: 0.024},
        {x: 16, y: 0.039},
        {x: 32, y: 0.067},
        {x: 64, y: 0.101},
        {x: 128, y: 0.205},
        {x: 256, y: 0.288}
    ];
    // Fit line: align = 0.005 * batch^0.74
    var fitPoints = [];
    for (var b = 8; b <= 256; b += 1) {
        fitPoints.push({x: b, y: 0.005 * Math.pow(b, 0.74)});
    }
    new Chart(ctx, {
        type: 'scatter',
        data: {
            datasets: [
                {
                    label: 'Measured',
                    data: dataPoints,
                    backgroundColor: '#5b3a8c',
                    borderColor: '#5b3a8c',
                    pointRadius: 6,
                    pointHoverRadius: 8,
                    order: 1
                },
                {
                    label: 'Fit: 0.005 \u00b7 batch\u2070\u00b7\u2077\u2074',
                    data: fitPoints,
                    type: 'line',
                    borderColor: '#5b3a8c',
                    borderWidth: 1.5,
                    pointRadius: 0,
                    fill: false,
                    tension: 0,
                    order: 2
                }
            ]
        },
        options: {
            responsive: true,
            plugins: {
                title: {
                    display: true,
                    text: 'Alignment ~ batch\u2070\u00b7\u2077\u2074 (R\u00b2=0.985)',
                    font: { size: 15 }
                },
                legend: { display: false }
            },
            scales: {
                x: {
                    type: 'logarithmic',
                    title: { display: true, text: 'Batch Size' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                },
                y: {
                    type: 'logarithmic',
                    title: { display: true, text: 'Inter-batch Alignment' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                }
            }
        }
    });
})();

// --- Chart 4: Vocab Size vs lm_head Ratio (log-log) ---
(function() {
    var ctx = document.getElementById('vocabLmHeadChart').getContext('2d');
    var dataPoints = [
        {x: 512, y: 3.7},
        {x: 1024, y: 6.0},
        {x: 2048, y: 9.5},
        {x: 4096, y: 13.6},
        {x: 8192, y: 18.9}
    ];
    // Fit line: ratio = 0.098 * vocab^0.59
    var fitPoints = [];
    for (var v = 512; v <= 8192; v += 10) {
        fitPoints.push({x: v, y: 0.098 * Math.pow(v, 0.59)});
    }
    new Chart(ctx, {
        type: 'scatter',
        data: {
            datasets: [
                {
                    label: 'Measured',
                    data: dataPoints,
                    backgroundColor: '#a82020',
                    borderColor: '#a82020',
                    pointRadius: 6,
                    pointHoverRadius: 8,
                    order: 1
                },
                {
                    label: 'Fit: 0.098 \u00b7 vocab\u2070\u00b7\u2075\u2079',
                    data: fitPoints,
                    type: 'line',
                    borderColor: '#a82020',
                    borderWidth: 1.5,
                    pointRadius: 0,
                    fill: false,
                    tension: 0,
                    order: 2
                }
            ]
        },
        options: {
            responsive: true,
            plugins: {
                title: {
                    display: true,
                    text: 'lm_head ratio ~ vocab\u2070\u00b7\u2075\u2079 (R\u00b2=0.987)',
                    font: { size: 15 }
                },
                legend: { display: false }
            },
            scales: {
                x: {
                    type: 'logarithmic',
                    title: { display: true, text: 'Vocab Size' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                },
                y: {
                    type: 'logarithmic',
                    title: { display: true, text: 'lm_head Sensitivity Ratio' },
                    grid: { color: '#d4cfc4' },
                    ticks: {
                        callback: function(val) { return val; }
                    }
                }
            }
        }
    });
})();
</script>
</body>
</html>
